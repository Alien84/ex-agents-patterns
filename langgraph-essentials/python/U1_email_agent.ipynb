{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f3905b",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 5em\">ðŸ¦œ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bd8e5-f539-4f58-822c-2db46990f4bd",
   "metadata": {},
   "source": [
    "# __LangGraph Essentials__\n",
    "# Build A Workflow\n",
    "<div style=\"display:flex; align-items:flex-start;\">\n",
    "  <img src=\"assets/EmailWorkflow.png\" width=\"600\" style=\"margin-right:15px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea634b-118c-4204-9385-c17a77ca62d1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f1916-5a59-4ea4-a9fb-35c9eae39b63",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda43634-cfde-45c3-ac0c-00203a11ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "path = find_dotenv()\n",
    "print(\"Loaded env from:\", path)\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14584f8e-8ab3-402d-8fef-d88783f21b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os\n",
    "from typing import Literal, TypedDict\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5206c1",
   "metadata": {},
   "source": [
    "# Define state schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0864ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Define the structure for email classification\n",
    "class EmailClassification(TypedDict):\n",
    "    intent: Literal[\"question\", \"bug\", \"billing\", \"feature\", \"complex\"]\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\", \"critical\"]\n",
    "    topic: str\n",
    "    summary: str\n",
    "\n",
    "class EmailAgentState(TypedDict):\n",
    "    # Raw email data\n",
    "    email_content: str\n",
    "    sender_email: str\n",
    "    email_id: str\n",
    "\n",
    "    # Classification result\n",
    "    classification: EmailClassification | None\n",
    "\n",
    "    # Raw search/API results\n",
    "    search_results: list[str] | None  # List of raw document chunks\n",
    "    customer_history: dict | None  # Raw customer data from CRM\n",
    "\n",
    "    # Generated content\n",
    "    draft_response: str | None\n",
    "    messages: list[str] | None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db6048",
   "metadata": {},
   "source": [
    "# Define Nodes, Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaecaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import interrupt, Command, RetryPolicy\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "def read_email(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Extract and parse email content\"\"\"\n",
    "    # In production, this would connect to your email service\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=f\"Processing email: {state['email_content']}\")]\n",
    "    }\n",
    "\n",
    "def classify_intent(state: EmailAgentState) -> Command[Literal[\"search_documentation\", \"human_review\", \"draft_response\", \"bug_tracking\"]]:\n",
    "    \"\"\"Use LLM to classify email intent and urgency, then route accordingly\"\"\"\n",
    "\n",
    "    # Create structured LLM that returns EmailClassification dict\n",
    "    structured_llm = llm.with_structured_output(EmailClassification)\n",
    "\n",
    "    # Format the prompt on-demand, not stored in state\n",
    "    classification_prompt = f\"\"\"\n",
    "    Analyze this customer email and classify it:\n",
    "\n",
    "    Email: {state['email_content']}\n",
    "    From: {state['sender_email']}\n",
    "\n",
    "    Provide classification including intent, urgency, topic, and summary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get structured response directly as dict\n",
    "    classification = structured_llm.invoke(classification_prompt)\n",
    "\n",
    "    # Determine next node based on classification\n",
    "    if classification['intent'] == 'billing' or classification['urgency'] == 'critical':\n",
    "        goto = \"human_review\"\n",
    "    elif classification['intent'] in ['question', 'feature']:\n",
    "        goto = \"search_documentation\"\n",
    "    elif classification['intent'] == 'bug':\n",
    "        goto = \"bug_tracking\"\n",
    "    else:\n",
    "        goto = \"draft_response\"\n",
    "\n",
    "    # Store classification as a single dict in state\n",
    "    return Command(\n",
    "        update={\"classification\": classification},\n",
    "        goto=goto\n",
    "    )\n",
    "\n",
    "def search_documentation(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    \"\"\"Search knowledge base for relevant information\"\"\"\n",
    "\n",
    "    # Build search query from classification\n",
    "    classification = state.get('classification', {})\n",
    "    query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n",
    "\n",
    "    try:\n",
    "        # Implement your search logic here\n",
    "        # Store raw search results, not formatted text\n",
    "        search_results = [\n",
    "            \"Reset password via Settings > Security > Change Password\",\n",
    "            \"Password must be at least 12 characters\",\n",
    "            \"Include uppercase, lowercase, numbers, and symbols\"\n",
    "        ]\n",
    "    except SearchAPIError as e:\n",
    "        # For recoverable search errors, store error and continue\n",
    "        search_results = [f\"Search temporarily unavailable: {str(e)}\"]\n",
    "\n",
    "    return Command(\n",
    "        update={\"search_results\": search_results},  # Store raw results or error\n",
    "        goto=\"draft_response\"\n",
    "    )\n",
    "\n",
    "def bug_tracking(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    \"\"\"Create or update bug tracking ticket\"\"\"\n",
    "\n",
    "    # Create ticket in your bug tracking system\n",
    "    ticket_id = \"BUG-12345\"  # Would be created via API\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"search_results\": [f\"Bug ticket {ticket_id} created\"],\n",
    "            \"current_step\": \"bug_tracked\"\n",
    "        },\n",
    "        goto=\"draft_response\"\n",
    "    )\n",
    "\n",
    "def draft_response(state: EmailAgentState) -> Command[Literal[\"human_review\", \"send_reply\"]]:\n",
    "    \"\"\"Generate response using context and route based on quality\"\"\"\n",
    "\n",
    "    classification = state.get('classification', {})\n",
    "\n",
    "    # Format context from raw state data on-demand\n",
    "    context_sections = []\n",
    "\n",
    "    if state.get('search_results'):\n",
    "        # Format search results for the prompt\n",
    "        formatted_docs = \"\\n\".join([f\"- {doc}\" for doc in state['search_results']])\n",
    "        context_sections.append(f\"Relevant documentation:\\n{formatted_docs}\")\n",
    "\n",
    "    if state.get('customer_history'):\n",
    "        # Format customer data for the prompt\n",
    "        context_sections.append(f\"Customer tier: {state['customer_history'].get('tier', 'standard')}\")\n",
    "\n",
    "    # Build the prompt with formatted context\n",
    "    draft_prompt = f\"\"\"\n",
    "    Draft a response to this customer email:\n",
    "    {state['email_content']}\n",
    "\n",
    "    Email intent: {classification.get('intent', 'unknown')}\n",
    "    Urgency level: {classification.get('urgency', 'medium')}\n",
    "\n",
    "    {chr(10).join(context_sections)}\n",
    "\n",
    "    Guidelines:\n",
    "    - Be professional and helpful\n",
    "    - Address their specific concern\n",
    "    - Use the provided documentation when relevant\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(draft_prompt)\n",
    "\n",
    "    # Determine if human review needed based on urgency and intent\n",
    "    needs_review = (\n",
    "        classification.get('urgency') in ['high', 'critical'] or\n",
    "        classification.get('intent') == 'complex'\n",
    "    )\n",
    "\n",
    "    # Route to appropriate next node\n",
    "    goto = \"human_review\" if needs_review else \"send_reply\"\n",
    "\n",
    "    return Command(\n",
    "        update={\"draft_response\": response.content},  # Store only the raw response\n",
    "        goto=goto\n",
    "    )\n",
    "\n",
    "def human_review(state: EmailAgentState) -> Command[Literal[\"send_reply\", END]]:\n",
    "    \"\"\"Pause for human review using interrupt and route based on decision\"\"\"\n",
    "\n",
    "    classification = state.get('classification', {})\n",
    "\n",
    "    # interrupt() must come first - any code before it will re-run on resume\n",
    "    human_decision = interrupt({\n",
    "        \"email_id\": state.get('email_id',''),\n",
    "        \"original_email\": state.get('email_content',''),\n",
    "        \"draft_response\": state.get('draft_response',''),\n",
    "        \"urgency\": classification.get('urgency'),\n",
    "        \"intent\": classification.get('intent'),\n",
    "        \"action\": \"Please review and approve/edit this response\"\n",
    "    })\n",
    "\n",
    "    # Now process the human's decision\n",
    "    if human_decision.get(\"approved\"):\n",
    "        return Command(\n",
    "            update={\"draft_response\": human_decision.get(\"edited_response\", state.get('draft_response',''))},\n",
    "            goto=\"send_reply\"\n",
    "        )\n",
    "    else:\n",
    "        # Rejection means human will handle directly\n",
    "        return Command(update={}, goto=END)\n",
    "\n",
    "def send_reply(state: EmailAgentState) -> dict:\n",
    "    \"\"\"Send the email response\"\"\"\n",
    "    # Integrate with email service\n",
    "    print(f\"Sending reply: {state['draft_response'][:100]}...\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a65993",
   "metadata": {},
   "source": [
    "# Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import RetryPolicy\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(EmailAgentState)\n",
    "\n",
    "# Add nodes with appropriate error handling\n",
    "workflow.add_node(\"read_email\", read_email)\n",
    "workflow.add_node(\"classify_intent\", classify_intent)\n",
    "\n",
    "# Add retry policy for nodes that might have transient failures\n",
    "workflow.add_node(\n",
    "    \"search_documentation\",\n",
    "    search_documentation,\n",
    "    retry_policy=RetryPolicy(max_attempts=3)\n",
    ")\n",
    "workflow.add_node(\"bug_tracking\", bug_tracking)\n",
    "workflow.add_node(\"draft_response\", draft_response)\n",
    "workflow.add_node(\"human_review\", human_review)\n",
    "workflow.add_node(\"send_reply\", send_reply)\n",
    "\n",
    "# Add only the essential edges\n",
    "workflow.add_edge(START, \"read_email\")\n",
    "workflow.add_edge(\"read_email\", \"classify_intent\")\n",
    "workflow.add_edge(\"send_reply\", END)\n",
    "\n",
    "# Compile with checkpointer for persistence, in case run graph with Local_Server --> Please compile without checkpointer\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5f56e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139cce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with urgent billing issue\n",
    "initial_state = {\n",
    "    \"email_content\": \"I was charged twice for my subscription! This is urgent!\",\n",
    "    \"sender_email\": \"customer@example.com\",\n",
    "    \"email_id\": \"email_123\"\n",
    "}\n",
    "\n",
    "# Run with a thread_id for persistence\n",
    "config = {\"configurable\": {\"thread_id\": \"customer_123\"}}\n",
    "result = app.invoke(initial_state, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f691a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph will pause at human_review\n",
    "print(f\"Draft ready for review: {result['draft_response'][:60]}...\\n\")\n",
    "\n",
    "# Provide human input to resume\n",
    "human_response = Command(\n",
    "    resume = {\n",
    "        \"approved\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Resume execution\n",
    "final_result = app.invoke(human_response, config)\n",
    "print(\"Email sent successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_content = [\n",
    "    \"I was charged two times for my subscription! This is urgent!\",\n",
    "    \"I was wondering if this was available in blue?\",\n",
    "    \"Can you tell me how long the sale is on?\",\n",
    "    \"The tire won't stay on the car!\",\n",
    "    \"My subscription is going to end in a few months, what is the new rate?\"\n",
    "]\n",
    "needs_approval = []\n",
    "\n",
    "for i, content in enumerate(email_content): \n",
    "\n",
    "    initial_state = {\n",
    "        \"email_content\": content,\n",
    "        \"sender_email\": \"customer@example.com\",\n",
    "        \"email_id\": f\"email_{i}\",\n",
    "    }\n",
    "    print(f\"{initial_state['email_id']}: \", end=\"\")\n",
    "\n",
    "    thread_id = uuid.uuid4()\n",
    "    config =  {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    result = app.invoke(initial_state, config)\n",
    "    if \"__interrupt__\" in result.keys():\n",
    "        result['thread_id'] = thread_id\n",
    "        needs_approval.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8084333",
   "metadata": {},
   "source": [
    ">LangSmith Trace - [Start-to-End](https://smith.langchain.com/public/3898d0d0-c934-4681-b325-7c4e1e88a826/r)  \n",
    ">LangSmith Trace - [Interrupt](https://smith.langchain.com/public/c23a3aed-cfa8-42aa-8f1e-78f58941aecd/r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-agents-patterns (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
