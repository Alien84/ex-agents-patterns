{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b046caf",
   "metadata": {},
   "source": [
    "<img src=\"assets/Agents.png\" align=\"left\" width=\"600\" style=\"margin-right:15px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005828f",
   "metadata": {},
   "source": [
    "Agents are typically implemented as an LLM performing actions using tools. They operate in continuous feedback loops, and are used in situations where problems and solutions are unpredictable. Agents have more autonomy than workflows, and can make decisions about the tools they use and how to solve problems. You can still define the available toolset and guidelines for how agents behave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded env from: /Users/alien110/Documents/ex-agents-patterns/.env\n",
      "OPENAI_API_KEY=****EjUA\n",
      "ANTHROPIC_API_KEY=****wwAA\n",
      "LANGSMITH_TRACING_V2=true\n",
      "LANGSMITH_ENDPOINT=****.com\n",
      "LANGSMITH_API_KEY=****d3f4\n",
      "LANGSMITH_PROJECT=****ials\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from typing import Annotated, List\n",
    "import operator\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "path = find_dotenv()\n",
    "print(\"Loaded env from:\", path)\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(path)\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply `a` and `b`.\n",
    "\n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds `a` and `b`.\n",
    "\n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide `a` and `b`.\n",
    "\n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# Augment the LLM with tools\n",
    "tools = [add, multiply, divide]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def llm_call(state: MessagesState):\n",
    "    \"\"\"LLM decides whether to call a tool or not\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(\n",
    "                [\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    \"\"\"Performs the tool call\"\"\"\n",
    "\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "\n",
    "# Conditional edge function to route to the tool node or end based upon whether the LLM made a tool call\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    \"\"\"Decide if we should continue the loop or stop based upon whether the LLM made a tool call\"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # If the LLM makes a tool call, then perform an action\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"\n",
    "\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",\n",
    "    should_continue,\n",
    "    [\"tool_node\", END]\n",
    ")\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")\n",
    "\n",
    "# Compile the agent\n",
    "agent = agent_builder.compile()\n",
    "\n",
    "# Show the agent\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "messages = [HumanMessage(content=\"Add 3 and 4.\")]\n",
    "messages = agent.invoke({\"messages\": messages})\n",
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-agents-patterns (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
