{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b046caf",
   "metadata": {},
   "source": [
    "<img src=\"assets/Evaluator-optimizer.png\" align=\"left\" width=\"600\" style=\"margin-right:15px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005828f",
   "metadata": {},
   "source": [
    "In evaluator-optimizer workflows, one LLM call creates a response and the other evaluates that response. If the evaluator or a human-in-the-loop determines the response needs refinement, feedback is provided and the response is recreated. This loop continues until an acceptable response is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "from typing_extensions import Literal\n",
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import display, Image\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "path = find_dotenv()\n",
    "print(\"Loaded env from:\", path)\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(path)\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Literal\n",
    "import operator\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    response: str\n",
    "    scenario: str\n",
    "    feedback: str\n",
    "    quality: str\n",
    "\n",
    "\n",
    "# Schema for structured output to use in evaluation\n",
    "class Feedback(BaseModel):\n",
    "    grade: Literal[\"excellent\", \"needs improvement\"] = Field(\n",
    "        description=\"Decide if the customer service response is excellent or needs improvement.\",\n",
    "    )\n",
    "    feedback: str = Field(\n",
    "        description=\"If the response needs improvement, provide specific feedback on how to enhance it for better customer satisfaction and professionalism.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "evaluator = llm.with_structured_output(Feedback)\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def llm_call_generator(state: State):\n",
    "    \"\"\"LLM generates a customer service response\"\"\"\n",
    "\n",
    "    if state.get(\"feedback\"):\n",
    "        msg = llm.invoke(\n",
    "            f\"Write a professional customer service response for BT to this scenario: {state['scenario']}. Take into account this feedback: {state['feedback']}\"\n",
    "        )\n",
    "    else:\n",
    "        msg = llm.invoke(f\"Write a professional, empathetic customer service response for BT to this scenario: {state['scenario']}\")\n",
    "    return {\"response\": msg.content}\n",
    "\n",
    "\n",
    "def llm_call_evaluator(state: State):\n",
    "    \"\"\"LLM evaluates the customer service response\"\"\"\n",
    "\n",
    "    grade = evaluator.invoke(f\"Evaluate this BT customer service response for professionalism, empathy, and problem-solving: {state['response']}\")\n",
    "    return {\"quality\": grade.grade, \"feedback\": grade.feedback}\n",
    "\n",
    "\n",
    "# Conditional edge function to route back to response generator or end based upon feedback from the evaluator\n",
    "def route_response(state: State):\n",
    "    \"\"\"Route back to response generator or end based upon feedback from the evaluator\"\"\"\n",
    "\n",
    "    if state[\"quality\"] == \"excellent\":\n",
    "        return \"Accepted\"\n",
    "    elif state[\"quality\"] == \"needs improvement\":\n",
    "        return \"Rejected + Feedback\"\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "optimizer_builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes\n",
    "optimizer_builder.add_node(\"llm_call_generator\", llm_call_generator)\n",
    "optimizer_builder.add_node(\"llm_call_evaluator\", llm_call_evaluator)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "optimizer_builder.add_edge(START, \"llm_call_generator\")\n",
    "optimizer_builder.add_edge(\"llm_call_generator\", \"llm_call_evaluator\")\n",
    "optimizer_builder.add_conditional_edges(\n",
    "    \"llm_call_evaluator\",\n",
    "    route_response,\n",
    "    {  # Name returned by route_response : Name of next node to visit\n",
    "        \"Accepted\": END,\n",
    "        \"Rejected + Feedback\": \"llm_call_generator\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile the workflow\n",
    "optimizer_workflow = optimizer_builder.compile()\n",
    "\n",
    "# Show the workflow\n",
    "display(Image(optimizer_workflow.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "# state = optimizer_workflow.invoke({\"scenario\": \"Customer's broadband has been down for 2 days and they're working from home\"})\n",
    "# print(state[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c82e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "\n",
    "# Clear cell output\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Create all widgets fresh\n",
    "scenario_input = widgets.Textarea(\n",
    "    value='Customer is experiencing slow 5G speeds in central London and is frustrated about missing important video calls',\n",
    "    placeholder='Enter a customer service scenario...',\n",
    "    description='Scenario:',\n",
    "    continuous_update=False,\n",
    "    layout=widgets.Layout(width='600px', height='80px')\n",
    ")\n",
    "\n",
    "submit_btn = widgets.Button(\n",
    "    description='Generate Response',\n",
    "    button_style='primary',\n",
    "    icon='comments'\n",
    ")\n",
    "\n",
    "result_html = widgets.HTML(value='')\n",
    "\n",
    "def on_button_click(btn):\n",
    "    \"\"\"Handle button click\"\"\"\n",
    "    scenario = scenario_input.value.strip()\n",
    "\n",
    "    if not scenario:\n",
    "        result_html.value = \"<p>‚ö†Ô∏è Please enter a customer service scenario!</p>\"\n",
    "        return\n",
    "\n",
    "    # Show loading state\n",
    "    btn.disabled = True\n",
    "    result_html.value = f\"<p>üîÑ Generating customer service response...</p>\"\n",
    "\n",
    "    try:\n",
    "        # Invoke workflow\n",
    "        state = optimizer_workflow.invoke({\"scenario\": scenario})\n",
    "\n",
    "        # Get the final response and quality\n",
    "        response = state.get('response', '')\n",
    "        quality = state.get('quality', '')\n",
    "        feedback = state.get('feedback', '')\n",
    "\n",
    "        # Determine quality badge\n",
    "        if quality == \"excellent\":\n",
    "            quality_badge = \"<span style='background: #28a745; color: white; padding: 5px 10px; border-radius: 3px; font-weight: bold;'>‚úì EXCELLENT</span>\"\n",
    "        else:\n",
    "            quality_badge = \"<span style='background: #ffc107; color: black; padding: 5px 10px; border-radius: 3px; font-weight: bold;'>‚ö† NEEDS IMPROVEMENT</span>\"\n",
    "\n",
    "        # Build HTML string with results\n",
    "        html = f\"\"\"\n",
    "        <div style=\"font-family: 'Segoe UI', Arial, sans-serif; padding: 20px; background: #f8f9fa; border-radius: 8px;\">\n",
    "            <div style=\"display: flex; align-items: center; margin-bottom: 15px;\">\n",
    "                <h3 style=\"color: #5514B4; margin: 0; flex-grow: 1;\">BT Customer Service Response Generator</h3>\n",
    "                {quality_badge}\n",
    "            </div>\n",
    "            <hr style=\"border: 1px solid #5514B4; margin-bottom: 20px;\">\n",
    "\n",
    "            <div style=\"margin: 20px 0;\">\n",
    "                <h4 style=\"color: #5514B4; margin-bottom: 10px;\">Customer Scenario</h4>\n",
    "                <div style=\"background: white; padding: 15px; border-left: 4px solid #5514B4; border-radius: 4px;\">\n",
    "                    <p style=\"margin: 0; color: #333;\">{scenario}</p>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <div style=\"margin: 20px 0;\">\n",
    "                <h4 style=\"color: #5514B4; margin-bottom: 10px;\">Generated Response</h4>\n",
    "                <div style=\"background: white; padding: 15px; border-left: 4px solid #28a745; border-radius: 4px;\">\n",
    "                    <div style=\"white-space: pre-wrap; color: #333;\">{response}</div>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <div style=\"margin-top: 20px; padding: 15px; background: #e8f4f8; border-radius: 4px; border-left: 4px solid #0066cc;\">\n",
    "                <h4 style=\"color: #0066cc; margin-top: 0; margin-bottom: 10px;\">Evaluation Results</h4>\n",
    "                <p style=\"margin: 5px 0;\"><strong>Quality Grade:</strong> {quality}</p>\n",
    "                {f'<p style=\"margin: 5px 0;\"><strong>Evaluator Feedback:</strong> {feedback}</p>' if feedback else ''}\n",
    "                <p style=\"margin: 10px 0 5px 0; font-size: 0.9em; color: #666;\"><em>This response was automatically evaluated and refined using an evaluator-optimizer workflow pattern to ensure the highest quality customer service.</em></p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        result_html.value = html\n",
    "\n",
    "    except Exception as e:\n",
    "        result_html.value = f\"<p>‚ùå Error: {str(e)}</p>\"\n",
    "\n",
    "    finally:\n",
    "        btn.disabled = False\n",
    "\n",
    "# Attach handler\n",
    "submit_btn.on_click(on_button_click)\n",
    "\n",
    "# Display\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h2 style='color: #5514B4;'>üéØ BT Customer Service AI - Evaluator-Optimizer Pattern</h2>\"),\n",
    "    widgets.HTML(\"\"\"\n",
    "    <div style=\"background: #f0f0f0; padding: 15px; border-radius: 5px; margin-bottom: 15px;\">\n",
    "        <h4 style=\"margin-top: 0;\">How This Works:</h4>\n",
    "        <ol style=\"margin-bottom: 0;\">\n",
    "            <li><strong>Generator:</strong> AI creates a professional customer service response</li>\n",
    "            <li><strong>Evaluator:</strong> Another AI evaluates the response for quality, empathy, and professionalism</li>\n",
    "            <li><strong>Optimizer Loop:</strong> If response needs improvement, feedback is provided and the response is regenerated</li>\n",
    "            <li><strong>Final Output:</strong> Only excellent responses are approved and delivered</li>\n",
    "        </ol>\n",
    "        <p style=\"margin-bottom: 0;\"><strong>Example Scenarios:</strong></p>\n",
    "        <ul style=\"margin-top: 5px; margin-bottom: 0;\">\n",
    "            <li>\"Customer's fiber broadband installation was missed for the third time\"</li>\n",
    "            <li>\"Business customer experiencing intermittent 5G connectivity affecting critical operations\"</li>\n",
    "            <li>\"Customer received an unexpectedly high bill and is threatening to switch providers\"</li>\n",
    "            <li>\"Smart home devices stopped working after recent network upgrade\"</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \"\"\"),\n",
    "    widgets.HBox([submit_btn]),\n",
    "    scenario_input,\n",
    "    result_html\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg-essentials (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
