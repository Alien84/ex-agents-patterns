{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b046caf",
   "metadata": {},
   "source": [
    "<img src=\"assets/Orchestrator.png\" align=\"left\" width=\"600\" style=\"margin-right:15px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005828f",
   "metadata": {},
   "source": [
    "Orchestrator-worker workflows provide more flexibility and are often used when subtasks cannot be predefined the way they can with parallelization. This happens with we cannot predetermine the tasks.\n",
    "\n",
    "In an orchestrator-worker configuration, the orchestrator:\n",
    "Breaks down tasks into subtasks\n",
    "Delegates subtasks to workers\n",
    "Synthesizes worker outputs into a final result\n",
    "\n",
    "Orchestrator-worker workflows are common and LangGraph has built-in support for them. The Send API lets you dynamically create worker nodes and send them specific inputs. Each worker has its own state, and all worker outputs are written to a shared state key that is accessible to the orchestrator graph. This gives the orchestrator access to all worker output and allows it to synthesize them into a final output. The example below iterates over a list of sections and uses the Send API to send a section to each worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "path = find_dotenv()\n",
    "print(\"Loaded env from:\", path)\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(path)\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487f95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "import operator\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\")\n",
    "\n",
    "# Schema for structured output to use in planning\n",
    "class Section(BaseModel):\n",
    "    name: str = Field(\n",
    "        description=\"Name for this section of the report.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
    "    )\n",
    "\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: List[Section] = Field(\n",
    "        description=\"Sections of the report.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "planner = llm.with_structured_output(Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f487392",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = planner.invoke('write a report for langgarph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb472a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Send\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, Image\n",
    "\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    topic: str  # Report topic\n",
    "    sections: list[Section]  # List of report sections\n",
    "    completed_sections: Annotated[\n",
    "        list, operator.add\n",
    "    ]  # All workers write to this key in parallel\n",
    "    final_report: str  # Final report\n",
    "\n",
    "\n",
    "# Worker state\n",
    "class WorkerState(TypedDict):\n",
    "    section: Section\n",
    "    completed_sections: Annotated[list, operator.add]\n",
    "\n",
    "\n",
    "# Nodes\n",
    "def orchestrator(state: State):\n",
    "    \"\"\"Orchestrator that generates a plan for the report\"\"\"\n",
    "\n",
    "    # Generate queries\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Generate a plan for the report.\"),\n",
    "            HumanMessage(content=f\"Here is the report topic: {state['topic']}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"sections\": report_sections.sections}\n",
    "\n",
    "\n",
    "def llm_call(state: WorkerState):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "\n",
    "    # Generate section\n",
    "    section = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=\"Write a concise report section following the provided name and description. IMPORTANT: Keep the section to a maximum of 3 sentences. Include no preamble. Use markdown formatting.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"Here is the section name: {state['section'].name} and description: {state['section'].description}\"\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Write the updated section to completed sections\n",
    "    return {\"completed_sections\": [section.content]}\n",
    "\n",
    "\n",
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "\n",
    "    # List of completed sections\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    # Format completed section to str to use as context for final sections\n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "\n",
    "    return {\"final_report\": completed_report_sections}\n",
    "\n",
    "\n",
    "# Conditional edge function to create llm_call workers that each write a section of the report\n",
    "def assign_workers(state: State):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "\n",
    "    # Kick off section writing in parallel via Send() API\n",
    "    return [Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]]\n",
    "\n",
    "\n",
    "# Build workflow\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "\n",
    "# Add the nodes\n",
    "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
    "orchestrator_worker_builder.add_node(\"llm_call\", llm_call)\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# Add edges to connect nodes\n",
    "orchestrator_worker_builder.add_edge(START, \"orchestrator\")\n",
    "orchestrator_worker_builder.add_conditional_edges(\n",
    "    \"orchestrator\", assign_workers, [\"llm_call\"]\n",
    ")\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\")\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "orchestrator_worker = orchestrator_worker_builder.compile()\n",
    "\n",
    "# Show the workflow\n",
    "display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Invoke\n",
    "# state = orchestrator_worker.invoke({\"topic\": \"Create a report on LLM scaling laws\"})\n",
    "\n",
    "# from IPython.display import Markdown\n",
    "# Markdown(state[\"final_report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a77ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "\n",
    "# Clear cell output\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Create all widgets fresh\n",
    "topic_input = widgets.Text(\n",
    "    value='Create a report on LLM scaling laws',\n",
    "    placeholder='Enter your report topic...',\n",
    "    description='Topic:',\n",
    "    continuous_update=False,\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "submit_btn = widgets.Button(\n",
    "    description='Generate Report',\n",
    "    button_style='primary',\n",
    "    icon='file-text'\n",
    ")\n",
    "\n",
    "result_html = widgets.HTML(value='')\n",
    "\n",
    "def on_button_click(btn):\n",
    "    \"\"\"Handle button click\"\"\"\n",
    "    topic = topic_input.value.strip()\n",
    "\n",
    "    if not topic:\n",
    "        result_html.value = \"<p>‚ö†Ô∏è Please enter a report topic!</p>\"\n",
    "        return\n",
    "\n",
    "    # Show loading state\n",
    "    btn.disabled = True\n",
    "    result_html.value = f\"<p>üîÑ Generating report on: {topic}...</p>\"\n",
    "\n",
    "    try:\n",
    "        # Invoke workflow\n",
    "        state = orchestrator_worker.invoke({\"topic\": topic})\n",
    "\n",
    "        # Get the sections and final report\n",
    "        sections = state.get('sections', [])\n",
    "        final_report = state.get('final_report', '')\n",
    "\n",
    "        # Build section list HTML\n",
    "        section_list = \"\"\n",
    "        for i, section in enumerate(sections, 1):\n",
    "            section_list += f\"<li><strong>{section.name}</strong>: {section.description}</li>\"\n",
    "\n",
    "        # Build HTML string with results\n",
    "        html = f\"\"\"\n",
    "        <div style=\"font-family: 'Segoe UI', Arial, sans-serif; padding: 15px; background: #f8f9fa; border-radius: 5px;\">\n",
    "            <h3 style=\"color: #0066cc; margin-top: 0;\">üìÑ Report: {topic}</h3>\n",
    "            <hr style=\"border: 1px solid #0066cc;\">\n",
    "\n",
    "            <div style=\"margin: 20px 0;\">\n",
    "                <h4 style=\"color: #0066cc;\">Generated Sections ({len(sections)})</h4>\n",
    "                <div style=\"background: white; padding: 15px; border-left: 3px solid #0066cc; margin-top: 10px;\">\n",
    "                    <ul>{section_list}</ul>\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <div style=\"margin: 20px 0;\">\n",
    "                <h4 style=\"color: #0066cc;\">Final Report</h4>\n",
    "                <div style=\"background: white; padding: 15px; border-left: 3px solid #28a745; margin-top: 10px;\">\n",
    "                    <div style=\"white-space: pre-wrap; font-family: 'Segoe UI', Arial, sans-serif;\">{final_report}</div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        result_html.value = html\n",
    "\n",
    "    except Exception as e:\n",
    "        result_html.value = f\"<p>‚ùå Error: {str(e)}</p>\"\n",
    "\n",
    "    finally:\n",
    "        btn.disabled = False\n",
    "\n",
    "# Attach handler\n",
    "submit_btn.on_click(on_button_click)\n",
    "\n",
    "# Display\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üìù Orchestrator-Worker Report Generator</h3>\"),\n",
    "    widgets.HTML(\"\"\"<p>Enter a topic and the system will orchestrate multiple workers to generate a comprehensive report:</p>\n",
    "    <ul>\n",
    "        <li><strong>Orchestrator:</strong> Creates a plan and breaks down the report into sections</li>\n",
    "        <li><strong>Workers:</strong> Each worker writes one section of the report in parallel</li>\n",
    "        <li><strong>Synthesizer:</strong> Combines all sections into a final comprehensive report</li>\n",
    "    </ul>\n",
    "    <p><em>Examples: \"LLM scaling laws\", \"Impact of climate change on agriculture\", \"Quantum computing applications\"</em></p>\"\"\"),\n",
    "    widgets.HBox([topic_input, submit_btn]),\n",
    "    result_html\n",
    "]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg-essentials (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
